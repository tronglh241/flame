core:
  data:
    train:
      module: torch.utils.data
      class: DataLoader
      kwargs:
        dataset:
          module: torchvision.datasets
          class: MNIST
          kwargs:
            root: '''dataset/MNIST/'''
            train: True
            download: True
            transform: transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])
        batch_size: 128
        shuffle: False

    train_eval:
      module: torch.utils.data
      class: DataLoader
      kwargs:
        dataset:
          module: torchvision.datasets
          class: MNIST
          kwargs:
            root: '''dataset/MNIST/'''
            train: True
            download: True
            transform: transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])
        batch_size: 128
        shuffle: False

    valid:
      module: torch.utils.data
      class: DataLoader
      kwargs:
        dataset:
          module: torchvision.datasets
          class: MNIST
          kwargs:
            root: '''dataset/MNIST/'''
            train: False
            download: True
            transform: transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])
        batch_size: 128
        shuffle: False

  loss:
    module: flame.core.loss.loss
    class: Loss
    kwargs:
      loss_fn:
        module: torch.nn
        class: NLLLoss
      output_transform: 'lambda x: x'

  model:
    module: flame.core.model.net
    class: Net

  optim:
    module: torch.optim
    class: SGD
    kwargs:
      params: core.model.parameters()
      lr: 0.01
      momentum: 0.9

  engine:
    module: flame.core.engine.engine
    class: Trainer
    kwargs:
      model: core.model
      data: core.data.train
      loss: core.loss
      optim: core.optim
      device: '''cuda'''
      max_epochs: 100

handlers:
  evaluator:
    train:
      module: flame.core.engine.engine
      class: Evaluator
      kwargs:
        model: core.model
        data: core.data.train_eval
        device : '''cuda'''

    valid:
      module: flame.core.engine.engine
      class: Evaluator
      kwargs:
        model: core.model
        data: core.data.valid
        device : '''cuda'''

  metrics:
    module: flame.handlers.metrics
    class: Metrics
    kwargs:
      evaluators:
        - handlers.evaluator.train
        - handlers.evaluator.valid
      metrics:
        loss:
          module: ignite.metrics
          class: Loss
          kwargs:
            loss_fn:
              module: torch.nn
              class: NLLLoss

  logging:
    tensorboard:
      train:
        module: flame.handlers.tensorboard
        class: SummaryWriter
        kwargs:
          log_dir: '''runs/MNIST/train'''

      valid:
        module: flame.handlers.tensorboard
        class: SummaryWriter
        kwargs:
          log_dir: '''runs/MNIST/valid'''

    progress_bar:
      train:
        module: ignite.contrib.handlers
        class: ProgressBar
        kwargs:
          persist: True

      train_eval:
        module: ignite.contrib.handlers
        class: ProgressBar
        kwargs:
          persist: False
          desc: '''Train evaluating'''

      valid:
        module: ignite.contrib.handlers
        class: ProgressBar
        kwargs:
          persist: False
          desc: '''Valid evaluating'''

  early_stopping:
    module: flame.handlers.early_stopping
    class: EarlyStopping
    kwargs:
      patience: 5
      score_name: '''loss'''
      mode: '''min'''
      trainer: core.engine

  lr_scheduler:
    module: torch.optim.lr_scheduler
    class: ReduceLROnPlateau
    kwargs:
      optimizer: core.optim
      mode: '''min'''
      factor: 0.1
      patience: 2
      verbose: True

  terminate_on_nan:
    module: ignite.handlers
    class: TerminateOnNan

  checkpoint:
    best:
      module: flame.handlers.checkpoint
      class: BestCheckpointer
      kwargs:
        dirname: '''checkpoint/MNIST'''
        score_name: '''loss'''
        mode: '''min'''
        n_saved: 1

    backup:
      module: flame.handlers.checkpoint
      class: BackupCheckpointer
      kwargs:
        dirname: '''checkpoint/MNIST'''
        n_saved: 1
        saved_module_keys:
          - '''core.engine'''
          - '''core.model'''
          - '''core.optim'''
          - '''handlers.checkpoint.best'''
          - '''handlers.early_stopping'''
          - '''handlers.lr_scheduler'''
          - '''handlers.logging.tensorboard.train'''
          - '''handlers.logging.tensorboard.valid'''

setup:
  evaluator:
    train:
      engine: core.engine
      handler: handlers.evaluator.train.run
      event: Events.EPOCH_COMPLETED

    valid:
      engine: core.engine
      handler: handlers.evaluator.valid.run
      event: Events.EPOCH_COMPLETED

  metrics:
    engine: core.engine
    handler: handlers.metrics
    event: Events.STARTED

  logging:
    tensorboard:
      metrics:
        loss:
          - engine: core.engine
            handler: handlers.logging.tensorboard.train.add_scalar
            event: Events.ITERATION_COMPLETED
            handler_kwargs:
              tag: '''Training/loss'''
              scalar_value: core.engine.state.output
              global_step: core.engine.state.iteration

          - engine: handlers.evaluator.train
            handler: handlers.logging.tensorboard.train.add_scalar
            event: Events.COMPLETED
            handler_kwargs:
              tag: '''Evaluation/loss'''
              scalar_value: handlers.evaluator.train.state.metrics['loss']
              global_step: core.engine.state.epoch

          - engine: handlers.evaluator.valid
            handler: handlers.logging.tensorboard.valid.add_scalar
            event: Events.COMPLETED
            handler_kwargs:
              tag: '''Evaluation/loss'''
              scalar_value: handlers.evaluator.valid.state.metrics['loss']
              global_step: core.engine.state.epoch

      flush:
        - engine: core.engine
          handler: handlers.logging.tensorboard.train.flush
          event: Events.COMPLETED

        - engine: core.engine
          handler: handlers.logging.tensorboard.valid.flush
          event: Events.COMPLETED

    progress_bar:
      train:
        engine: core.engine
        handler: handlers.logging.progress_bar.train.attach
        event: Events.STARTED
        handler_kwargs:
          engine: core.engine
          output_transform: 'lambda x: {''loss'': x}'

      train_eval:
        engine: core.engine
        handler: handlers.logging.progress_bar.train_eval.attach
        event: Events.STARTED
        handler_kwargs:
          engine: handlers.evaluator.train

      valid:
        engine: core.engine
        handler: handlers.logging.progress_bar.valid.attach
        event: Events.STARTED
        handler_kwargs:
          engine: handlers.evaluator.valid

  early_stopping:
    engine: handlers.evaluator.valid
    handler: handlers.early_stopping
    event: Events.COMPLETED

  lr_scheduler:
    engine: handlers.evaluator.valid
    handler: handlers.lr_scheduler.step
    event: Events.COMPLETED
    handler_kwargs:
      metrics: handlers.evaluator.valid.state.metrics['loss']

  terminate_on_nan:
    engine: core.engine
    handler: handlers.terminate_on_nan
    event: Events.ITERATION_COMPLETED

  checkpoint:
    best:
      engine: handlers.evaluator.valid
      handler: handlers.checkpoint.best
      event: Events.COMPLETED

    backup:
      engine: handlers.evaluator.valid
      handler: handlers.checkpoint.backup
      event: Events.COMPLETED

extralibs:
  transforms: torchvision.transforms
  Events:
    module: ignite.engine
    name: Events
