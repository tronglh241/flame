core:
  data:
    train:
      module: torch.utils.data
      class: DataLoader
      DataLoader:
        dataset:
          module: torchvision.datasets
          class: MNIST
          MNIST:
            root: '''dataset/MNIST/'''
            train: True
            download: True
            transform: transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])
        batch_size: 128
        shuffle: False

    train_eval:
      module: torch.utils.data
      class: DataLoader
      DataLoader:
        dataset:
          module: torchvision.datasets
          class: MNIST
          MNIST:
            root: '''dataset/MNIST/'''
            train: True
            download: True
            transform: transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])
        batch_size: 128
        shuffle: False

    valid:
      module: torch.utils.data
      class: DataLoader
      DataLoader:
        dataset:
          module: torchvision.datasets
          class: MNIST
          MNIST:
            root: '''dataset/MNIST/'''
            train: False
            download: True
            transform: transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))])
        batch_size: 128
        shuffle: False

  loss:
    module: flame.core.loss.loss
    class: Loss
    Loss:
      loss_fn:
        module: torch.nn
        class: NLLLoss
      output_transform: 'lambda x: x'

  model:
    module: flame.core.model.net
    class: Net

  optim:
    module: torch.optim
    class: SGD
    SGD:
      params: core.model.parameters()
      lr: 0.01
      momentum: 0.9

  engine:
    module: flame.core.engine.engine
    class: Trainer
    Trainer:
      model: core.model
      data: core.data.train
      loss: core.loss
      optim: core.optim
      device: '''cuda'''
      max_epochs: 100

handlers:
  evaluator:
    train:
      module: flame.core.engine.engine
      class: Evaluator
      Evaluator:
        model: core.model
        data: core.data.train_eval
        device : '''cuda'''

    valid:
      module: flame.core.engine.engine
      class: Evaluator
      Evaluator:
        model: core.model
        data: core.data.valid
        device : '''cuda'''

  metrics:
    loss:
      module: ignite.metrics
      class: Loss
      Loss:
        loss_fn:
          module: torch.nn
          class: NLLLoss

  logging:
    tensorboard:
      train:
        module: flame.handlers.tensorboard
        class: SummaryWriter
        SummaryWriter:
          log_dir: '''runs/MNIST/train'''

      valid:
        module: flame.handlers.tensorboard
        class: SummaryWriter
        SummaryWriter:
          log_dir: '''runs/MNIST/valid'''

    progress_bar:
      train:
        module: ignite.contrib.handlers
        class: ProgressBar
        ProgressBar:
          persist: True

      train_eval:
        module: ignite.contrib.handlers
        class: ProgressBar
        ProgressBar:
          persist: False
          desc: '''Train evaluating'''

      valid:
        module: ignite.contrib.handlers
        class: ProgressBar
        ProgressBar:
          persist: False
          desc: '''Valid evaluating'''

  early_stopping:
    module: ignite.handlers
    class: EarlyStopping
    EarlyStopping:
      patience: 5
      score_function: 'lambda engine: - engine.state.metrics[''loss'']'
      trainer: core.engine

  lr_scheduler:
    module: torch.optim.lr_scheduler
    class: ReduceLROnPlateau
    ReduceLROnPlateau:
      optimizer: core.optim
      mode: '''min'''
      factor: 0.1
      patience: 2
      verbose: True

  terminate_on_nan:
    module: ignite.handlers
    class: TerminateOnNan

  checkpoint:
    best:
      module: flame.handlers.checkpoint
      class: ModelCheckpoint
      ModelCheckpoint:
        dirname: '''checkpoint/MNIST'''
        filename_prefix: '''best'''
        score_function: 'lambda engine: - engine.state.metrics[''loss'']'
        score_name: '''loss'''
        n_saved: 1
        global_step_transform: global_step_from_engine(core.engine, Events.EPOCH_STARTED)

    backup:
      module: flame.handlers.checkpoint
      class: ModelCheckpoint
      ModelCheckpoint:
        dirname: '''checkpoint/MNIST'''
        filename_prefix: '''backup'''
        n_saved: 1
        global_step_transform: global_step_from_engine(core.engine, Events.EPOCH_STARTED)
        include_self: True

setup:
  evaluator:
    train:
      engine: core.engine
      handler: handlers.evaluator.train.run
      event: Events.EPOCH_COMPLETED

    valid:
      engine: core.engine
      handler: handlers.evaluator.valid.run
      event: Events.EPOCH_COMPLETED

  metrics:
    loss:
      - engine: core.engine
        handler: handlers.metrics.loss.attach
        event: Events.STARTED
        handler_kwargs:
          engine: handlers.evaluator.train
          name: '''loss'''

      - engine: core.engine
        handler: handlers.metrics.loss.attach
        event: Events.STARTED
        handler_kwargs:
          engine: handlers.evaluator.valid
          name: '''loss'''

  logging:
    tensorboard:
      metrics:
        loss:
          - engine: core.engine
            handler: handlers.logging.tensorboard.train.add_scalar
            event: Events.ITERATION_COMPLETED
            handler_kwargs:
              tag: '''Training/loss'''
              scalar_value: core.engine.state.output
              global_step: core.engine.state.iteration

          - engine: handlers.evaluator.train
            handler: handlers.logging.tensorboard.train.add_scalar
            event: Events.COMPLETED
            handler_kwargs:
              tag: '''Evaluation/loss'''
              scalar_value: handlers.evaluator.train.state.metrics['loss']
              global_step: core.engine.state.epoch

          - engine: handlers.evaluator.valid
            handler: handlers.logging.tensorboard.valid.add_scalar
            event: Events.COMPLETED
            handler_kwargs:
              tag: '''Evaluation/loss'''
              scalar_value: handlers.evaluator.valid.state.metrics['loss']
              global_step: core.engine.state.epoch

      flush:
        - engine: core.engine
          handler: handlers.logging.tensorboard.train.flush
          event: Events.COMPLETED

        - engine: core.engine
          handler: handlers.logging.tensorboard.valid.flush
          event: Events.COMPLETED

    progress_bar:
      train:
        engine: core.engine
        handler: handlers.logging.progress_bar.train.attach
        event: Events.STARTED
        handler_kwargs:
          engine: core.engine
          output_transform: 'lambda x: {''loss'': x}'

      train_eval:
        engine: core.engine
        handler: handlers.logging.progress_bar.train_eval.attach
        event: Events.STARTED
        handler_kwargs:
          engine: handlers.evaluator.train

      valid:
        engine: core.engine
        handler: handlers.logging.progress_bar.valid.attach
        event: Events.STARTED
        handler_kwargs:
          engine: handlers.evaluator.valid

  early_stopping:
    engine: handlers.evaluator.valid
    handler: handlers.early_stopping
    event: Events.COMPLETED

  lr_scheduler:
    engine: handlers.evaluator.valid
    handler: handlers.lr_scheduler.step
    event: Events.COMPLETED
    handler_kwargs:
      metrics: handlers.evaluator.valid.state.metrics['loss']

  terminate_on_nan:
    engine: core.engine
    handler: handlers.terminate_on_nan
    event: Events.ITERATION_COMPLETED

  checkpoint:
    best:
      engine: handlers.evaluator.valid
      handler: handlers.checkpoint.best
      event: Events.COMPLETED
      handler_kwargs:
        to_save:
          model: core.model

    backup:
      engine: handlers.evaluator.valid
      handler: handlers.checkpoint.backup
      event: Events.COMPLETED
      handler_kwargs:
        to_save:
          core.engine: core.engine
          core.model: core.model
          core.optim: core.optim
          handlers.checkpoint.best: handlers.checkpoint.best
          handlers.early_stopping: handlers.early_stopping
          handlers.lr_scheduler: handlers.lr_scheduler
          handlers.logging.tensorboard.train: handlers.logging.tensorboard.train
          handlers.logging.tensorboard.valid: handlers.logging.tensorboard.valid
          _config_: global_cfg

extralibs:
  transforms: torchvision.transforms
  Events:
    module: ignite.engine
    name: Events
  global_step_from_engine:
    module: ignite.handlers
    name: global_step_from_engine
  global_cfg:
    module: flame.core.config.config
    name: global_cfg
